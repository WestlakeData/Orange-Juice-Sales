  ---
title: \vspace{6cm}\LARGE Orange Juice Sales at Wasatch Grocery Chain
subtitle: "Identification of Significant Predictor Variables and Predictive Modelling of Customer Preferance in Minute Maid Sales"
author: "Chris Gearheart and Chris Porter"
date: "`r Sys.Date()`"
output: pdf_document
---

\newpage

```{r library calls, include=FALSE, warning=FALSE}
library(tidyverse)
library(tidymodels)
library(caret)
library(corrplot)
library(xgboost)
library(vip)
library(DALEXtra)
library(ROCR)
library(dplyr)
library(plotROC)
library(glmnet)

```

## Introduction
Wasatch Grocery Chain (WGC) is a regional grocery chain operating in the Intermoutain West of the US. WGC sells two brands of orange juice in its stores, Citrus Hill (CH) and Minute Maid (MM) of which MM is the more profitable to the company.  This report will identify what customer factors within available data contribute to purchase of MM over CH, as well as to what degree these factors influence customer choice.  In addition, a predictive model is created that will allow the Sales Department to identify other customers within our customer base that are more likely to purchase Minute Maid brand orange juice, thus driving profitability across the company.

```{r setup}
set.seed(1234)
df <- read.csv(url("http://data.mishra.us/files/project/OJ_data.csv"))
df[-1] <- lapply(df[-1],as.numeric)
df$Purchase <- as.factor(df$Purchase)
purchase_testtrain <- initial_split(df, prop = 0.75, strata = Purchase)
train <- training(purchase_testtrain)
test <- testing(purchase_testtrain)


```

### Available Data 
The data set used in this report contains 13 possible predictor variables as well as 1 outcome variable, Purchase, which records whether or not a customer purchased MM.  There are a total of 1070 observations in the data set.  The data set was further partitioned into a **training** data set, containing `r nrow(train)` observations, and a validation **testing** data set containing `r nrow(test)` observations.

## Methods

<!-- To be filled out once analysis has been completed -->

## Results

1.	What predictor variables influence the purchase of MM?
2.	Are all the variables in the dataset effective or are some more effective than others?
3.	How confident are you in your recommendations?
4.	Based on your analysis what are the specific recommendations you have for the brand manager?

```{r logistic regression - Pre-processing, warning=FALSE}

set.seed(1234)

# Pre-processing
# Dummy variables are unnecessary because only `Purchase` is a factor, and it's already expressed using dummy variables.

# No columns are uniformly filled with one unique value — there is spread in each of the 13 independent variables.
summary(train)

# There is no missing data — imputation is not necessary
sum(is.na(train))

# A correlogram of our data set confirms that several variables are highly correlated -- a sure sign of multicollinearity. 

corr <- cor(df[-1]) 
corr %>% cor() %>% corrplot()
```
Gearheart @ Porter: I worry I may be overthinking this, but I couldn't find anything from our class material that concretely explained how to handle multicollinearity in the context of a logistic regression, so I drew on our class materials from Algos for Business Decisions. 

Pros: 

The code below performs a logistic regression, but it uses Lasso (`alpha = 1`), giving us something to say about the magnitude and direction of variables, plus which variables' influences were shrunk to zero when all variables were regressed against each other (`Price MM`, `Disc CH`, `SalePriceCH`, and `PctDiscCH`). *Doing that gives us an AUC of 0.9*, and that's *after* inline k-fold validation of 7 when training the model.

Cons: 

If the goal is to imitate the kind of information given to us in the class, the things below are missing. Which ones you think are work including before we submit?
  + Model comparison of AUC charts comparing more than one models
  + A confusion matrix for this model. The approach doesn't add columns to the `test` sheet with binary predictions that are easy to compose the matrix. Do you think it's worth it to do that?
  + Charts graphically showing the effect of different variables on `Purchase`.


```{r logistic regression - Option 1 - Drawn from Algos for Buss Dec class , warning=FALSE}

predictors <- train[,c(2:13)]
purchase_only <- train$Purchase

str(predictors)

predMod <- glm(train$Purchase ~ ., data = train, family = binomial(link='logit'))

predictors <- data.matrix(predictors)

set.seed(1234)
cv.binomial <- cv.glmnet(x = predictors, y = train$Purchase,
                         alpha = 1, family = "binomial",
                         nfolds = 7, standardize = TRUE, type.measure = "auc")

plot(cv.binomial)

(best.lambda <- cv.binomial$lambda.min)
y4<- coef(cv.binomial, s="lambda.min", exact=FALSE)
print(y4)


test_predictors <- test[,c(2:13)]
test_predictors <- data.matrix(test_predictors)
pred <- predict(cv.binomial, newx = test_predictors, 
               type = "response", s ="lambda.min")
pred <- prediction(pred, test$Purchase)
perf <- performance(pred,"tpr","fpr")
auc_ROCR<- performance(pred,measure ="auc")

plot(perf,colorize=FALSE, col="black") 
lines(c(0,1),c(0,1),col = "gray", lty = 4 )
text(1,0.15,labels=paste("AUC = ",round(auc_ROCR@y.values[[1]],
                                        digits=2),sep=""),adj=1)



```

Gearheart @ Porter: This is more in line with what we were provided this term, but I haven't cracked how to get a tidy AUC printout. 

```{r logistic regression - , warning=FALSE}

# Logistic regression model with all variables
logmod1 <- glm(Purchase ~ ., data = train,family=binomial(link='logit'))
summary(logmod1)
summary(logmod1)$aic
DescTools::PseudoR2(logmod1, which = "McFaddenAdj")

# Making and processing predictions for cross-validation with test set
test$prediction <- predict(logmod1, newdata = test, type ="response")
test$binary_prediction <- ifelse(test$prediction > 0.5,1,0)
test$binary_prediction <- as.factor(test$binary_prediction)

# Comparing predictions for accuracy against test set
test <- test %>% mutate(accurate = 1*(binary_prediction == Purchase))
accuracy <- sum(test$accurate)/nrow(test)

print (paste("Accuracy:",round(accuracy,3)))

t(confusionMatrix(test$binary_prediction, test$Purchase, positive = "1")$table)
confusionMatrix(test$binary_prediction, test$Purchase, positive = "1")$byClass


# Logistic regression with only the significant variables
logmod2 <- glm(Purchase ~ PriceDiff + LoyalCH, data = train,family=binomial(link='logit'))

summary(logmod2)
summary(logmod2)$aic
DescTools::PseudoR2(logmod2, which = "McFaddenAdj")

# Making and processing predictions for cross-validation with test set
test$predictionL <- predict(logmod2, newdata = test, type ="response")
test$binary_predictionL <- ifelse(test$predictionL > 0.5,1,0)
test$binary_predictionL <- as.factor(test$binary_predictionL)

# Testing predictions for accuracy against test set
test <- test %>% mutate(accurateL = 1*(binary_predictionL == Purchase))
accuracyL <- sum(test$accurateL)/nrow(test)

print (paste("Accuracy:",round(accuracyL,3)))

t(confusionMatrix(test$binary_prediction4, test$Purchase, positive = "1")$table)
confusionMatrix(test$binary_prediction4, test$Purchase, positive = "1")$byClass


print (paste("Accuracy with four variables:",round(accuracy4,3)))
```


```{r boosted trees model tuning, warning=FALSE, echo=TRUE}
set.seed(1234)
recipe_oj <- recipe(Purchase ~ ., train)

model_oj_bt <- boost_tree(trees = tune(), tree_depth = tune(), learn_rate = tune()) %>%
  set_engine('xgboost', verbosity = 0) %>%
  set_mode('classification')

hyperparameter_grid <- grid_regular(trees(), tree_depth(), learn_rate(), levels = 5)

purchase_folds <- vfold_cv(train, v=4) # 4-fold Cross validation

oj_workflow <- workflow() %>% add_model(model_oj_bt) %>% add_recipe(recipe_oj) #Set Workflow

# Tune Hyper-parameters
oj_tune <- oj_workflow %>% tune_grid(resamples = purchase_folds,
                                     grid = hyperparameter_grid,
                                     metrics = metric_set(accuracy))

best_bt_model <- oj_tune %>% select_best('accuracy') #Select best Hyper-parameters from grid

#best_bt_model

```


The hyperparameters for number of trees, tree depth, and learn rate for the boosted tree model were tuned using a grid with 5 levels and 4-fold cross validation.  Hyperparameter performance was evaluated by overall model accuracy of prediction. The final hyperparameters for the model are number of trees (`r best_bt_model$trees`), tree depth (`r best_bt_model$tree_depth`), and learn rate (`r best_bt_model$learn_rate`).

```{r boosted trees final model, warning=FALSE, echo=TRUE}

oj_final_workflow <- oj_workflow %>% finalize_workflow(best_bt_model) # Create Final Workflow based upon selected hyperparameters

final_fit <- oj_final_workflow %>% last_fit(split = purchase_testtrain) # Final Fit Model

final_fit %>% collect_metrics()

oj_final_workflow %>% fit(data = train) %>% extract_fit_parsnip() %>% vip(geom = 'col') #Plot most important variables based upon Variable Importance metric


vi_values <- oj_final_workflow %>% fit(data = train) %>% extract_fit_parsnip() %>% vi()

vi_values

```

the most important variable is `r vi_values$Variable[1]` with a `r round(vi_values$Importance[1] *100, 2)`%, followed by `r vi_values$Variable[2]` with a `r round(vi_values$Importance[2] *100, 2)`%

```{r XAI, warning=FALSE, echo=TRUE}

model_fitted <- oj_final_workflow %>% fit(data = train)

explainer_rf <- explain_tidymodels(model_fitted, 
                                   data = train[,-1], 
                                   y = train$Purchase, 
                                   type = "pdp",verbose = FALSE)

pdp_LoyalCH <- model_profile(explainer_rf, 
                             variables = "LoyalCH", 
                             N=NULL)
pdp_PriceDiff <- model_profile(explainer_rf, 
                                variables = "PriceDiff", 
                                N=NULL)
pdp_DiscCH <- model_profile(explainer_rf, 
                             variables = "DiscCH", 
                             N=NULL)
pdp_ListPriceDiff <- model_profile(explainer_rf, 
                             variables = "ListPriceDiff", 
                             N=NULL)
pdp_SalePriceMM <- model_profile(explainer_rf, 
                             variables = "SalePriceMM", 
                             N=NULL)
pdp_DiscMM <- model_profile(explainer_rf, 
                             variables = "DiscMM", 
                             N=NULL)

plot(pdp_LoyalCH)
plot(pdp_PriceDiff)
#plot(pdp_DiscCH)
#plot(pdp_ListPriceDiff)
#plot(pdp_SalePriceMM)
#plot(pdp_DiscMM)

```

## Conclusions and Recommendations

### Brand

### Sales

## Appendix 1: Data Characteristics
```{r Appendix 1 Data Characteristics, echo=TRUE, warning=FALSE}
summary(df)
summary(test)
summary(train) #need to equalize the 0/1 split in train data set

corr <- cor(df[-1]) #correlogram of numeric variables, excluding outcome variable
testDf <- cor.mtest(df[-1], conf.level = 0.95) #compute significance of correlation
# Plot correlogram
corrplot(corr, p.mat = testDf$p, method = 'number', type = 'lower', insig='blank', 
         addCoef.col ='black', number.cex = 0.6, order = 'AOE', diag=FALSE, tl.srt = 45, tl.col = 'black')


```
