---
title: \vspace{6cm}\LARGE Orange Juice Sales at Wasatch Grocery Chain
subtitle: "Identification of Significant Predictor Variables and Predictive Modelling of Customer Preferance in Minute Maid Sales"
author: "Chris Gearheart and Chris Porter"
date: "`r Sys.Date()`"
output: pdf_document
---

\newpage

```{r library calls, include=FALSE, warning=FALSE}
library(tidyverse)
library(tidymodels)
library(caret)
library(corrplot)
library(xgboost)
library(vip)
library(DALEXtra)
```

## Introduction
Wasatch Grocery Chain (WGC) is a regional grocery chain operating in the Intermoutain West of the US. WGC sells two brands of orange juice in its stores, Citrus Hill (CH) and Minute Maid (MM) of which MM is the more profitable to the company.  This report will identify what customer factors within available data contribute to purchase of MM over CH, as well as to what degree these factors influence customer choice.  In addition, a predictive model is created that will allow the Sales Department to identify other customers within our customer base that are more likely to purchase Minute Maid brand orange juice, thus driving profitability across the company.

```{r setup}
set.seed(1234)
df <- read.csv(url("http://data.mishra.us/files/project/OJ_data.csv"))
df[-1] <- lapply(df[-1],as.numeric)
df$Purchase <- as.factor(df$Purchase)
purchase_testtrain <- initial_split(df, prop = 0.75, strata = Purchase)
train <- training(purchase_testtrain)
test <- testing(purchase_testtrain)


```

### Available Data 
The data set used in this report contains 13 possible predictor variables as well as 1 outcome variable, Purchase, which records whether or not a customer purchased MM.  There are a total of 1070 observations in the data set.  The data set was further partitioned into a **training** data set, containing `r nrow(train)` observations, and a validation **testing** data set containing `r nrow(test)` observations.

## Methods

<!-- To be filled out once analysis has been completed -->

## Results

```{r brand analysis, warning=FALSE}

```



```{r boosted trees model tuning, warning=FALSE, echo=TRUE}
set.seed(1234)
recipe_oj <- recipe(Purchase ~ ., train)

model_oj_bt <- boost_tree(trees = tune(), tree_depth = tune(), learn_rate = tune()) %>%
  set_engine('xgboost', verbosity = 0) %>%
  set_mode('classification')

hyperparameter_grid <- grid_regular(trees(), tree_depth(), learn_rate(), levels = 5)

purchase_folds <- vfold_cv(train, v=4) # 4-fold Cross validation

oj_workflow <- workflow() %>% add_model(model_oj_bt) %>% add_recipe(recipe_oj) #Set Workflow

# Tune Hyper-parameters
oj_tune <- oj_workflow %>% tune_grid(resamples = purchase_folds,
                                     grid = hyperparameter_grid,
                                     metrics = metric_set(accuracy))

best_bt_model <- oj_tune %>% select_best('accuracy') #Select best Hyper-parameters from grid

best_bt_model

```

```{r boosted trees final model, warning=FALSE, echo=TRUE}

oj_final_workflow <- oj_workflow %>% finalize_workflow(best_bt_model) # Create Final Workflow based upon selected hyperparameters

final_fit <- oj_final_workflow %>% last_fit(split = purchase_testtrain) # Final Fit Model

final_fit %>% collect_metrics()

oj_final_workflow %>% fit(data = train) %>% extract_fit_parsnip() %>% vip(geom = 'col') #Plot most important variables based upon Variable Importance metric

vi_values <- oj_final_workflow %>% fit(data = train) %>% extract_fit_parsnip() %>% vi()
vi_gt_1 <- vi_values %>% filter(Importance >= 0.01)
vi_gt_1

```

the most important variable is `r vi_values$Variable[1]` with a `r round(vi_values$Importance[1] *100, 4)`%

```{r XAI, warning=FALSE, echo=TRUE}

model_fitted <- oj_final_workflow %>% fit(data = train)

explainer_rf <- explain_tidymodels(model_fitted, 
                                   data = train[,-1], 
                                   y = train$Purchase, 
                                   type = "pdp",verbose = FALSE)

pdp_LoyalCH <- model_profile(explainer_rf, 
                             variables = "LoyalCH", 
                             N=NULL)
pdp_PriceDiff <- model_profile(explainer_rf, 
                                variables = "PriceDiff", 
                                N=NULL)
pdp_DiscCH <- model_profile(explainer_rf, 
                             variables = "DiscCH", 
                             N=NULL)
pdp_ListPriceDiff <- model_profile(explainer_rf, 
                             variables = "ListPriceDiff", 
                             N=NULL)
pdp_SalePriceMM <- model_profile(explainer_rf, 
                             variables = "SalePriceMM", 
                             N=NULL)
pdp_DiscMM <- model_profile(explainer_rf, 
                             variables = "DiscMM", 
                             N=NULL)

plot(pdp_LoyalCH)
plot(pdp_PriceDiff)
#plot(pdp_DiscCH)
#plot(pdp_ListPriceDiff)
#plot(pdp_SalePriceMM)
#plot(pdp_DiscMM)

```

## Conclusions and Recommendations

### Brand

### Sales

## Appendix 1: Data Characteristics
```{r Appendix 1 Data Characteristics, echo=TRUE, warning=FALSE}
summary(df)
summary(test)
summary(train) #need to equalize the 0/1 split in train data set

corr <- cor(df[-1]) #correlogram of numeric variables, excluding outcome variable
testDf <- cor.mtest(df[-1], conf.level = 0.95) #compute significance of correlation
# Plot correlogram
corrplot(corr, p.mat = testDf$p, method = 'number', type = 'lower', insig='blank', 
         addCoef.col ='black', number.cex = 0.6, order = 'AOE', diag=FALSE, tl.srt = 45, tl.col = 'black')





# TEST TEST TEST Chris gearheart's test 


```
